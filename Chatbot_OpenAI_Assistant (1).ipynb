{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotsnagaur/ChatbotHopeHolisticCare/blob/Dev_Jyo_01/Chatbot_OpenAI_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenAi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLy6x4UMus3I",
        "outputId": "dfff9ffa-4e75-4362-f04a-db6868c932f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenAi\n",
            "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/267.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/267.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenAi) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from OpenAi) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from OpenAi)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from OpenAi) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from OpenAi) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from OpenAi) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from OpenAi) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAi) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAi) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAi) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->OpenAi)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->OpenAi)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAi) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAi) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, OpenAi\n",
            "Successfully installed OpenAi-1.16.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=\"")\n",
        "client"
      ],
      "metadata": {
        "id": "HA7glsvHJdop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b1e820-2488-4408-cac2-1e58ce880eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7a1a7bf98fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Upload File----JYO CHANGED HERE"
      ],
      "metadata": {
        "id": "jSO3_datOyJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the first JSON file\n",
        "uploaded_file_1 = client.files.create(\n",
        "    file=open(\"/content/policy.json\", 'rb'),\n",
        "    purpose='assistants',)\n",
        "\n",
        "# Upload the second JSON file\n",
        "uploaded_file_2 = client.files.create(\n",
        "    file=open(\"/content/incidents.json\", 'rb'),\n",
        "    purpose='assistants',)"
      ],
      "metadata": {
        "id": "D8Yc58PVCjhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_file_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnHtMZI7aw8B",
        "outputId": "66dfaf03-0fbe-4a28-cfa0-6e91436b44a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-Wnn7sAQy8m3CzY9VNh8ptUdN', bytes=206728, created_at=1712599979, filename='policy.json', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_file_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soJLSHdIC9t1",
        "outputId": "9b93f50c-e9f5-43d9-8dd4-45a65d35d2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-RMop7WGPCyRsJjmhMxDHtXea', bytes=171276, created_at=1712599979, filename='incidents.json', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Assistant--JYO CHANGED HERE\n"
      ],
      "metadata": {
        "id": "-gFb8p-MO6Cm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9CpYWwGIxMK"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=\"AI Assistent\",\n",
        "    instructions=\"You are a AI Assistant that answers staff member's queries related to aged care policies and incidents as per the data provided. Always mention the policy_name_ (key from your JSON) explicitly when referencing information from a policy. This could be in a format like Policy Name: [policy__name_ Key]. To answer any question, look inside the data first.  If the question is not related to provided files, you tell the staff to contact their manager because you do not have that information. Start your answers with a warm greeting. If the staff ask you in different language other than English, you answer them by their language.\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    file_ids=[uploaded_file_1.id, uploaded_file_2.id])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Thread"
      ],
      "metadata": {
        "id": "h91zPAXAO-yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "aFBhcp8AI6tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTkVBF44b33K",
        "outputId": "2e345190-425a-4c44-a4cf-17cedc563369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Thread(id='thread_xlpSPUlye0BIo1jyETj6ctWg', created_at=1712552002, metadata={}, object='thread')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ihK8N3hSM70W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Message Inside Thread"
      ],
      "metadata": {
        "id": "wM0X1ZRUPEcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"what to do incase I have covid infection?\" #ask for user input in this line\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6QFISagkJw89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#client.beta.threads.messages.list(thread_id=thread.id).data\n",
        "# client.beta.threads.messages.list(thread_id=thread.id).data[0].content[0].text.value"
      ],
      "metadata": {
        "id": "cctlqZDBMLwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run Assistent"
      ],
      "metadata": {
        "id": "UuVSLBSJPJpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        ")\n",
        "# run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "# run"
      ],
      "metadata": {
        "id": "wEpXo8P8LTJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2-wV6sK7KmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Retrive Assistant's Response"
      ],
      "metadata": {
        "id": "uij6eRS9PXc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "    if run.status==\"completed\":\n",
        "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "        latest_message = messages.data[0]\n",
        "        text = latest_message.content[0].text.value\n",
        "        print(text)\n",
        "        break;"
      ],
      "metadata": {
        "id": "WbQuRT7QLb7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab43f4a2-6918-4c88-e301-5e697bc2c874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings,\n",
            "\n",
            "If you have been infected with COVID, the following initial actions are generally recommended based on an occurrence reported in the incidents data:\n",
            "\n",
            "1. It is recommended to monitor any signs and symptoms of COVID closely. \n",
            "2. If you are experiencing severe symptoms such as high fever or shortness of breath, it is advisable to seek medical attention immediately.\n",
            "3. RAT (Rapid Antigen Test) may be performed to monitor the presence of the virus. Staff should take a RAT before their next shift to ensure safety.\n",
            "4. If you are living with someone who has tested positive, you are advised to maintain distance and follow appropriate precautions.\n",
            "\n",
            "Furthermore, under the Infection Prevention and Control Policy, standard precautions should be maintained which include respiratory hygiene and cough etiquette, hand hygiene after contact with respiratory secretions, and use of appropriate personal protective equipment (PPE) such as masks when entering a home with clients who require droplet precautions  .\n",
            "\n",
            "Please adhere to these guidelines and if you require additional guidance, ensure to follow the defined procedures in your organization's Infection Prevention and Control Policy or consult with your healthcare provider.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ohya4cwNfBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Hasan's Work"
      ],
      "metadata": {
        "id": "qJNlgB8szloY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"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\")\n",
        "\n",
        "uploaded_file = client.files.create(\n",
        "    file=open(\"/content/all_pdfs_text.txt\", 'rb'),\n",
        "    purpose='assistants',)\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"AI Assistent\",\n",
        "    instructions=\"You are a AI Assistant that answers any queries related to aged care policies and incidents as per the data provided.Look inside the data first. If the answer is not available then search the answer from the preset conditions. Start your answers with a warm greeting\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    file_ids=[uploaded_file.id]\n",
        ")\n",
        "\n",
        "\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"what number to dial in an emergency with a client?\") #ask for user input in this line\n",
        "\n",
        "\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id)\n",
        "\n",
        "while True:\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "    if run.status == \"completed\":\n",
        "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "        latest_message = messages.data[0]\n",
        "        text = latest_message.content[0].text.value\n",
        "        print(text)\n",
        "        break;\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOAUXl6bxLhc",
        "outputId": "3d43a1bb-0dff-4ae3-d8a7-fc5467ae053d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello,\n",
            "\n",
            "In an emergency with a client, workers must first contact emergency services if the situation warrants it. The document does not specify the exact number, but typically, emergency services can be reached by dialing 000 in Australia, 911 in the United States, 112 in the European Union, and other specific numbers depending on the country where services are provided. It is important for workers to be familiar with the local emergency number. After addressing the immediate situation by contacting emergency services, workers must then report all incidents internally to the Home Care Manager and follow further reporting procedures as required .\n",
            "\n",
            "Please ensure you are aware of the local emergency number to call in case of an incident with a client.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textt = (\"Hope Holistic Care is an organization that has implemented preventative measures \"\n",
        "         \"to ensure that individuals are free from discrimination, exploitation, abuse, harm, neglect, \"\n",
        "         \"and violence. Their policies and practices are designed to protect peoples \"\n",
        "         \"rights and empower individuals by informing them about their rights. They foster a \"\n",
        "         \"culture of preventing abuse with a commitment from all workers to undergo training in \"\n",
        "         \"abuse prevention and client rights. The staff recruitment process is thorough, and a holistic, \"\n",
        "         \"system-wide approach is adopted for preventing abuse across all services and activities. \"\n",
        "         \"The organization also places significant emphasis on creating a culture of reporting and \"\n",
        "         \"transparency, encouraging workers and clients to speak up about abuse without fear of retribution. \"\n",
        "         \"Whistleblower protections are in place to promote this transparency and ensure abuse does not go unreported. \"\n",
        "         \"Hope Holistic Care also ensures staff wellbeing and supports clients who report abuse by listening to \"\n",
        "         \"them, involving them in investigations, and keeping them informed on the measures being taken. An immediate response \"\n",
        "         \"is coordinated for allegations of abuse, which may include offering first aid, contact with emergency services, \"\n",
        "         \"legal, and other types of assistance as required.\")\n"
      ],
      "metadata": {
        "id": "YbauIJWHxzuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "id": "PtxsOlHD4s3E",
        "outputId": "d1eb79b6-1e83-4d8c-cc5b-7f1051e475fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "759"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-mention source of volume of policy in the answers\n",
        "-source file of pdfs can be updated/data storage issues\n",
        "-integrate to sharepoint and broadcast:\n",
        "\n",
        "-limitations and assumptions regarding cost per activity\n",
        "-app sumo where they promote apps-type of apps people are coming up with\n",
        "\n"
      ],
      "metadata": {
        "id": "LTQ3EaHWT2Dp"
      }
    }
  ]
}
